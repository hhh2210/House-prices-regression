# House Prices Regression - Advanced Ensemble Solution

## Background
Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.

With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.

## ç¡¬ä»¶æ”¯æŒ
- âœ… Macbook M4 (Apple Silicon MPS)
- âœ… GPU with CUDA (æ¨èï¼šå¤§æ˜¾å­˜GPUå¦‚L20 48GB)
- âœ… CPU fallback

## é¡¹ç›®ç»“æ„
```
House-prices-regression/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv          # è®­ç»ƒæ•°æ®
â”‚   â””â”€â”€ test.csv           # æµ‹è¯•æ•°æ®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_tree.py      # æ ‘æ¨¡å‹åŸºçº¿ï¼ˆXGBoost/LightGBM/RF/HGBï¼‰
â”‚   â”œâ”€â”€ train_ensemble.py  # CPU/GPU ensemble (XGBoost + LightGBM)
â”‚   â”œâ”€â”€ train_gpu_ensemble.py  # å®Œæ•´GPUåŠ é€Ÿensemble (NN + XGBoost + LightGBM)
â”‚   â””â”€â”€ train_mps.py       # PyTorch MLP (æ”¯æŒMPS/CUDA/CPU)
â”œâ”€â”€ submissions/           # ç”Ÿæˆçš„æäº¤æ–‡ä»¶
â”œâ”€â”€ pyproject.toml         # ä¾èµ–ç®¡ç†
â””â”€â”€ readme.md
```

## æ ¸å¿ƒæ€è·¯ä¸æ–¹æ³•

### 1. ç‰¹å¾å·¥ç¨‹ï¼ˆFeature Engineeringï¼‰

- ç›®æ ‡ä¸æŒ‡æ ‡
  - å¯¹ `SalePrice` åšå¯¹æ•°å˜æ¢ï¼ˆ`log1p`ï¼‰ï¼Œåœ¨å¯¹æ•°ç©ºé—´è®­ç»ƒï¼›éªŒè¯æŒ‡æ ‡ç”¨å¯¹æ•°ç©ºé—´çš„ RMSEï¼ˆæ¥è¿‘ç«èµ›çš„ RMSLEï¼‰ã€‚
**åŸºç¡€ç‰¹å¾**ï¼š
- é¢ç§¯æ±‡æ€»ï¼š`TotalSF`, `TotalPorchSF`
- æ—¶é—´ç‰¹å¾ï¼š`HouseAge`, `RemodAge`, `IsRemodeled`, `GarageAge`
- å«æµ´ç»Ÿè®¡ï¼š`TotalBath`ï¼ˆå…¨æµ´+åŠæµ´æƒé‡ï¼‰
- å­˜åœ¨æ€§æ ‡è®°ï¼š`HasBsmt`, `HasGarage`, `HasFireplace`, `HasPool`
- è´¨é‡æœ‰åºç¼–ç ï¼šå°† Ex/Gd/TA/Fa/Po æ˜ å°„ä¸ºæ•°å€¼

**é«˜çº§ç‰¹å¾**ï¼š
- äº¤äº’ç‰¹å¾ï¼š`QualArea = OverallQual Ã— GrLivArea`, `QualBathArea`, `BathArea`
- å¤šé¡¹å¼ç‰¹å¾ï¼šå…³é”®æ•°å€¼ç‰¹å¾çš„å¹³æ–¹ã€ç«‹æ–¹
- æ¯”ç‡ç‰¹å¾ï¼š`BathPerArea`, `LotAreaRatio`, `SFperBath`
- ååº¦å¤„ç†ï¼šå¯¹é«˜ååº¦æ•°å€¼ç‰¹å¾ï¼ˆ>0.75ï¼‰è¿›è¡Œ log1p è½¬æ¢

**æ•°æ®æ¸…æ´—**ï¼š
- é¢†åŸŸè§„åˆ™å¡«å……ï¼šå¯¹ç‰¹å®šç¼ºå¤±å€¼æŒ‰ç«èµ›è§„åˆ™å¤„ç†ï¼ˆå¦‚ NA â†’ "None"ï¼‰
- ç¦»ç¾¤ç‚¹ç§»é™¤ï¼šå»é™¤ `GrLivArea >= 4000` çš„å¼‚å¸¸æ ·æœ¬
- ç¤¾åŒºå¡«å……ï¼š`LotFrontage` æŒ‰ `Neighborhood` ä¸­ä½æ•°å¡«å……

### 2. æ¨¡å‹é›†æˆï¼ˆEnsemble Learningï¼‰

é‡‡ç”¨ **Stacking** ç­–ç•¥ï¼Œç»“åˆå¤šä¸ªæ¨¡å‹çš„ä¼˜åŠ¿ï¼š

**Level 1 Base Models**ï¼š
- **Deep Neural Network (PyTorch)**ï¼š512â†’256â†’128â†’64 å…¨è¿æ¥ç½‘ç»œï¼ŒBatchNorm + Dropout
- **XGBoost**ï¼šæ¢¯åº¦æå‡æ ‘ï¼ŒGPUåŠ é€Ÿï¼ˆdevice='cuda'ï¼‰
- **LightGBM**ï¼šè½»é‡çº§æ¢¯åº¦æå‡ï¼ŒGPUè®­ç»ƒ

**Level 2 Meta-Learner**ï¼š
- **Ridge Regression**ï¼šåŸºäº OOF predictions çš„çº¿æ€§é›†æˆ

**ä¼˜åŠ¿**ï¼š
- ç¥ç»ç½‘ç»œæ•è·éçº¿æ€§äº¤äº’
- æ ‘æ¨¡å‹å¤„ç†ç¨€ç–å’Œåˆ†ç±»ç‰¹å¾
- Ridgeå…ƒå­¦ä¹ å™¨è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜æƒé‡

### 3. GPU åŠ é€Ÿä¼˜åŒ–

**è®­ç»ƒåŠ é€Ÿ**ï¼š
- XGBoost: `device='cuda'`, `tree_method='hist'`
- LightGBM: `device='gpu'`ï¼ˆshould be careful with OpenCL for GPUï¼‰
- PyTorch: CUDAå¼ é‡ + DataLoaderæ‰¹å¤„ç†
- Early stoppingï¼šé¿å…è¿‡æ‹Ÿåˆå¹¶èŠ‚çœæ—¶é—´

**æ˜¾å­˜ä¼˜åŒ–**ï¼š
- 48GB L20 å¯åŒæ—¶è®­ç»ƒå¤§batch sizeï¼ˆ512-4096ï¼‰
- ç¥ç»ç½‘ç»œæ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰
- 5æŠ˜äº¤å‰éªŒè¯å¹¶è¡Œå¤„ç†


## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å®‰è£… uv åŒ…ç®¡ç†å™¨ï¼ˆäºŒé€‰ä¸€ï¼‰
brew install uv                        # macOS Homebrew
# æˆ–ï¼š
curl -LsSf https://astral.sh/uv/install.sh | sh

# å‡†å¤‡ç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
uv python install 3.11                 # å®‰è£… Python 3.11
uv sync                                # åŒæ­¥ä¾èµ–ï¼ˆåŸºäº pyproject.tomlï¼‰
```

### 2. é€‰æ‹©è®­ç»ƒè„šæœ¬

#### ğŸš€ æ–¹æ¡ˆä¸€ï¼šGPU å®Œæ•´ Ensembleï¼ˆæ¨èï¼Œæœ€ä½³æ€§èƒ½ï¼‰
**é€‚ç”¨**ï¼š48GB GPU (L20/A100)ï¼Œç›®æ ‡ RMSE ~0.11-0.12

```bash
# æ·±åº¦ç¥ç»ç½‘ç»œ + XGBoost + LightGBM ä¸‰æ¨¡å‹ stacking
uv run python src/train_gpu_ensemble.py --folds 5

# è®­ç»ƒé›†é¢å¤–å¹¶å…¥ AmesHousing.csvï¼ˆå¯é€‰ï¼‰
uv run python src/train_gpu_ensemble.py --folds 5 --include-ames --ames-path data/AmesHousing.csv
```

**ç‰¹ç‚¹**ï¼š
- 5æŠ˜äº¤å‰éªŒè¯ï¼Œè‡ªåŠ¨stacking
- å®Œæ•´ç‰¹å¾å·¥ç¨‹ï¼ˆ354ç»´ï¼‰
- GPUåŠ é€Ÿè®­ç»ƒï¼ˆNN + æ ‘æ¨¡å‹ï¼‰
- è¾“å‡ºï¼š`submissions/submission_gpu_ensemble.csv`

---

#### âš¡ æ–¹æ¡ˆäºŒï¼šæ ‘æ¨¡å‹åŸºçº¿ï¼ˆå¿«é€Ÿè°ƒå‚ï¼‰
**é€‚ç”¨**ï¼šCPU/GPUï¼Œå¿«é€Ÿè¿­ä»£

```bash
# XGBoostï¼ˆGPUåŠ é€Ÿ + è¶…å‚æ•°æœç´¢ï¼‰
uv run python src/train_tree.py --model xgb --gpu --folds 5

# è®­ç»ƒé›†é¢å¤–å¹¶å…¥ AmesHousing.csvï¼ˆå¯é€‰ï¼‰
uv run python src/train_tree.py --model xgb --gpu --folds 5 --include-ames --ames-path data/AmesHousing.csv

# å¸¦è¶…å‚æ•°æœç´¢ï¼ˆ20æ¬¡è¿­ä»£ï¼‰
uv run python src/train_tree.py --model xgb --tune --n_iter 20 --folds 3 --gpu

# LightGBMï¼ˆéœ€å…ˆå®‰è£…ï¼‰
uv add lightgbm
uv run python src/train_tree.py --model lgbm --gpu --folds 5

# HistGradientBoostingï¼ˆsklearnï¼ŒCPUå‹å¥½ï¼‰
uv run python src/train_tree.py --model hgb --folds 5
```

**å‚æ•°è¯´æ˜**ï¼š
- `--gpu`: å¯ç”¨GPUåŠ é€Ÿï¼ˆXGBoost/LightGBMï¼‰
- `--tune`: è¶…å‚æ•°æœç´¢ï¼ˆRandomizedSearchCVï¼‰
- `--n_iter`: æœç´¢è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤40ï¼‰
- `--folds`: KæŠ˜äº¤å‰éªŒè¯æŠ˜æ•°ï¼ˆé»˜è®¤5ï¼‰
- `--include-ames`: è®­ç»ƒé›†å¹¶å…¥ `AmesHousing.csv`
- `--ames-path`: æŒ‡å®š AmesHousing æ•°æ®è·¯å¾„ï¼ˆé»˜è®¤ `data/AmesHousing.csv`ï¼‰

---

#### ğŸ æ–¹æ¡ˆä¸‰ï¼šPyTorch MLPï¼ˆApple Silicon ä¼˜åŒ–ï¼‰
**é€‚ç”¨**ï¼šMacBook M4 (MPSåŠ é€Ÿ)

```bash
# ä½¿ç”¨ MPS åŠ é€Ÿ
uv run python src/train_mps.py --device mps --epochs 200 --batch_size 512

# CUDA GPU
uv run python src/train_mps.py --device cuda --epochs 300 --batch_size 1024

# è®­ç»ƒé›†é¢å¤–å¹¶å…¥ AmesHousing.csvï¼ˆå¯é€‰ï¼‰
uv run python src/train_mps.py --device mps --include-ames --ames-path data/AmesHousing.csv
```

---

## è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåï¼Œæäº¤æ–‡ä»¶ä¿å­˜åœ¨ `submissions/` ç›®å½•ï¼š

| æ–‡ä»¶å | å¯¹åº”è„šæœ¬ | è¯´æ˜ |
|--------|---------|------|
| `submission_gpu_ensemble.csv` | `train_gpu_ensemble.py` | GPUå®Œæ•´ensemble |
| `submission_tree_xgb_tuned.csv` | `train_tree.py --model xgb --tune` | XGBoostè°ƒå‚ç‰ˆ |
| `submission_tree_hgb.csv` | `train_tree.py --model hgb` | HGBåŸºçº¿ |
| `submission_pytorch_mlp.csv` | `train_mps.py` | PyTorch MLP |

## å¯è°ƒå‚æ•°

### train_gpu_ensemble.py
- `--folds`: KæŠ˜äº¤å‰éªŒè¯æ•°ï¼ˆé»˜è®¤5ï¼‰
- `--seed`: éšæœºç§å­ï¼ˆé»˜è®¤42ï¼‰

### train_tree.py
- `--model`: æ¨¡å‹é€‰æ‹©ï¼ˆhgb/rf/xgb/lgbmï¼Œé»˜è®¤hgbï¼‰
- `--folds`: äº¤å‰éªŒè¯æŠ˜æ•°ï¼ˆé»˜è®¤5ï¼‰
- `--tune`: å¯ç”¨è¶…å‚æ•°æœç´¢
- `--n_iter`: æœç´¢è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤40ï¼‰
- `--gpu`: å¯ç”¨GPUåŠ é€Ÿ
- `--log_target`: ç›®æ ‡å¯¹æ•°å˜æ¢ï¼ˆé»˜è®¤å¼€å¯ï¼‰
- `--remove_outliers`: ç§»é™¤ç¦»ç¾¤ç‚¹ï¼ˆé»˜è®¤å¼€å¯ï¼‰

### train_mps.py
- `--device`: è®¾å¤‡é€‰æ‹©ï¼ˆcpu/cuda/mpsï¼Œé»˜è®¤è‡ªåŠ¨ï¼‰
- `--epochs`: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤200ï¼‰
- `--batch_size`: æ‰¹å¤§å°ï¼ˆé»˜è®¤512ï¼‰
- `--hidden_dim`: éšè—å±‚ç»´åº¦ï¼ˆé»˜è®¤256ï¼‰
- `--layers`: éšè—å±‚æ•°ï¼ˆé»˜è®¤3ï¼‰
- `--lr`: å­¦ä¹ ç‡ï¼ˆé»˜è®¤0.001ï¼‰
- `--dropout`: Dropoutç‡ï¼ˆé»˜è®¤0.3ï¼‰

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å¦‚ä½•è¿›ä¸€æ­¥æå‡ (ç›®æ ‡ < 0.11)

1. **å¢åŠ æ¨¡å‹å¤šæ ·æ€§**
   - æ·»åŠ CatBooståˆ°ensemble
   - å°è¯•ä¸åŒçš„neural networkæ¶æ„
   - ä½¿ç”¨TabNetç­‰è¡¨æ ¼ä¸“ç”¨æ¨¡å‹

2. **é«˜çº§ç‰¹å¾å·¥ç¨‹**
   - Target encoding for neighborhood
   - æ›´å¤šäº¤äº’ç‰¹å¾ç»„åˆ
   - æ—¶åºç‰¹å¾ï¼ˆå»ºé€ å¹´ä»½å‘¨æœŸæ€§ï¼‰
   - å¤–éƒ¨æ•°æ®èåˆ

3. **ä¼˜åŒ–stackingç­–ç•¥**
   - å¤šå±‚stackingï¼ˆLevel 3ï¼‰
   - ä½¿ç”¨æ›´å¤æ‚çš„meta-learnerï¼ˆå¦‚LightGBMï¼‰
   - Out-of-fold predictions optimization

4. **è¶…å‚æ•°æ·±åº¦è°ƒä¼˜**
   - Optuna/Hyperoptæ›¿ä»£RandomizedSearchCV
   - å¢åŠ æœç´¢ç©ºé—´å’Œè¿­ä»£æ¬¡æ•°
   - é’ˆå¯¹ensembleæƒé‡çš„grid search


## é¡¹ç›®ä¾èµ–

æ ¸å¿ƒåº“ï¼š
- `numpy`, `pandas`: æ•°æ®å¤„ç†
- `scikit-learn`: é¢„å¤„ç†ã€CVã€meta-learner
- `torch`: ç¥ç»ç½‘ç»œè®­ç»ƒ
- `xgboost`: æ¢¯åº¦æå‡æ ‘ï¼ˆGPUæ”¯æŒï¼‰
- `lightgbm`: è½»é‡çº§GBDTï¼ˆGPUæ”¯æŒï¼‰
- `tqdm`: è¿›åº¦æ¡

## å‚è€ƒèµ„æ–™

- [Kaggle House Prices Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
- [XGBoost GPU Support](https://xgboost.readthedocs.io/en/latest/gpu/)
- [LightGBM GPU Tutorial](https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html)
- [PyTorch MPS Backend](https://pytorch.org/docs/stable/notes/mps.html)

## License

MIT
