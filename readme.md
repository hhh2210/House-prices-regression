# ğŸ  House Prices Regression - Advanced Ensemble Solution

<div align="center">

[![Kaggle](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=Kaggle&logoColor=white)](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)](LICENSE)

**ğŸ† Kaggle æ’å: Top 0.7% (33/4,692) | ğŸ“Š æœ€ä½³åˆ†æ•°: 0.02904**

*åŸºäºç‰¹å¾å·¥ç¨‹ã€é›†æˆå­¦ä¹ å’Œ GPU åŠ é€Ÿçš„é«˜æ€§èƒ½æˆ¿ä»·é¢„æµ‹è§£å†³æ–¹æ¡ˆ*

[ç‰¹æ€§](#-æ ¸å¿ƒç‰¹æ€§) â€¢ [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢ [å®éªŒç»“æœ](#-å®éªŒç»“æœ) â€¢ [æ–‡æ¡£](#-è¯¦ç»†æ–‡æ¡£)

</div>

---

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ [Kaggle House Prices Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) çš„å®Œæ•´è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡ 79 ä¸ªç‰¹å¾å˜é‡é¢„æµ‹ç¾å›½çˆ±è·åå·è‰¾å§†æ–¯å¸‚çš„ä½å®…é”€å”®ä»·æ ¼ã€‚

**æ ¸å¿ƒäº®ç‚¹**ï¼š
- ğŸ¯ **é«˜æ€§èƒ½**: Kaggle Public Leaderboard è¾¾åˆ° **0.02904** (Top 0.7%)
- ğŸš€ **å¤šç¡¬ä»¶æ”¯æŒ**: æ”¯æŒ CPU / CUDA / Apple MPS (M4) åŠ é€Ÿ
- ğŸ”¬ **æ™ºèƒ½è°ƒä¼˜**: é›†æˆ Optuna è´å¶æ–¯ä¼˜åŒ–ï¼Œæ•ˆç‡æå‡ 3-5 å€
- ğŸ“Š **æ•°æ®å¢å¼º**: æ”¯æŒ AmesHousing å¤–éƒ¨æ•°æ®é›†ï¼Œæ€§èƒ½æå‡ 77%
- ğŸ§ª **æ¨¡å‹ä¸°å¯Œ**: æä¾› XGBoost/LightGBM/PyTorch/Ensemble ç­‰å¤šç§æ–¹æ¡ˆ

## ğŸ›  æŠ€æœ¯æ ˆ

<div align="center">

### æ ¸å¿ƒæ¡†æ¶
![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat-square&logo=scikit-learn&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat-square&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat-square&logo=pandas&logoColor=white)

### æœºå™¨å­¦ä¹ åº“
![XGBoost](https://img.shields.io/badge/XGBoost-00A3E0?style=flat-square&logo=xgboost&logoColor=white)
![LightGBM](https://img.shields.io/badge/LightGBM-02569B?style=flat-square&logo=lightgbm&logoColor=white)
![Optuna](https://img.shields.io/badge/Optuna-00A3E0?style=flat-square&logo=optuna&logoColor=white)

### ç¡¬ä»¶åŠ é€Ÿ
![CUDA](https://img.shields.io/badge/CUDA-76B900?style=flat-square&logo=nvidia&logoColor=white)
![Apple Silicon](https://img.shields.io/badge/Apple_Silicon-000000?style=flat-square&logo=apple&logoColor=white)

</div>

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. ğŸ”¥ å“è¶Šæ€§èƒ½
| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **Kaggle æ’å** | **33 / 4,692** | Top 0.7% |
| **æœ€ä½³åˆ†æ•°** | **0.02904** | RMSE (log space) |
| **æå‡å¹…åº¦** | **-77.2%** | ä½¿ç”¨ AmesHousing æ•°æ®å¢å¼º |
| **è®­ç»ƒé€Ÿåº¦** | **10-20 åˆ†é’Ÿ** | 50 æ¬¡ Optuna è¯•éªŒ (GPU) |

### 2. ğŸ’¡ å…ˆè¿›æ–¹æ³•

#### ç‰¹å¾å·¥ç¨‹ (354 ç»´)
- âœ… **åŸºç¡€ç‰¹å¾**: é¢ç§¯æ±‡æ€»ã€æ—¶é—´ç‰¹å¾ã€å«æµ´ç»Ÿè®¡ã€å­˜åœ¨æ€§æ ‡è®°
- âœ… **äº¤äº’ç‰¹å¾**: `QualArea = OverallQual Ã— GrLivArea`ã€`BathArea`
- âœ… **å¤šé¡¹å¼ç‰¹å¾**: å…³é”®ç‰¹å¾çš„å¹³æ–¹ã€ç«‹æ–¹å˜æ¢
- âœ… **æ¯”ç‡ç‰¹å¾**: `BathPerArea`ã€`LotAreaRatio`ã€`SFperBath`
- âœ… **ååº¦å¤„ç†**: è‡ªåŠ¨æ£€æµ‹å¹¶å¯¹æ•°å˜æ¢é«˜ååº¦ç‰¹å¾ (>0.75)

#### æ¨¡å‹æ¶æ„
```
ğŸ“¦ Stacking Ensemble
â”œâ”€ ğŸ§  Deep Neural Network (PyTorch)
â”‚  â””â”€ 512â†’256â†’128â†’64 + BatchNorm + Dropout
â”œâ”€ ğŸŒ² XGBoost (GPU åŠ é€Ÿ)
â”‚  â””â”€ device='cuda' + tree_method='hist'
â”œâ”€ ğŸŒ¿ LightGBM (GPU åŠ é€Ÿ)
â”‚  â””â”€ device='gpu' + OpenCL
â””â”€ ğŸ“ˆ Ridge Meta-Learner
   â””â”€ åŸºäº OOF predictions
```

### 3. ğŸ›  å¤šç¡¬ä»¶æ”¯æŒ
- âœ… **Macbook M4** (Apple Silicon MPS)
- âœ… **GPU CUDA** (æ¨èï¼š48GB+ æ˜¾å­˜å¦‚ L20/A100)
- âœ… **CPU Fallback** (HistGradientBoosting ä¼˜åŒ–)

### 4. âš¡ æ™ºèƒ½ä¼˜åŒ–
- **Optuna è´å¶æ–¯ä¼˜åŒ–**: æ›¿ä»£éšæœºæœç´¢ï¼Œæ”¶æ•›é€Ÿåº¦å¿« 3-5 å€
- **TPE ç®—æ³•**: Tree-structured Parzen Estimator æ™ºèƒ½å‚æ•°é€‰æ‹©
- **MedianPruner**: è‡ªåŠ¨å‰ªæä½æ•ˆè¯•éªŒï¼ŒèŠ‚çœ 30-50% è®¡ç®—æ—¶é—´

## é¡¹ç›®ç»“æ„
```
House-prices-regression/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv          # è®­ç»ƒæ•°æ®
â”‚   â””â”€â”€ test.csv           # æµ‹è¯•æ•°æ®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_tree.py      # æ ‘æ¨¡å‹åŸºçº¿ï¼ˆXGBoost/LightGBM/RF/HGBï¼‰
â”‚   â”œâ”€â”€ train_ensemble.py  # CPU/GPU ensemble (XGBoost + LightGBM)
â”‚   â”œâ”€â”€ train_gpu_ensemble.py  # å®Œæ•´GPUåŠ é€Ÿensemble (NN + XGBoost + LightGBM)
â”‚   â””â”€â”€ train_mps.py       # PyTorch MLP (æ”¯æŒMPS/CUDA/CPU)
â”œâ”€â”€ submissions/           # ç”Ÿæˆçš„æäº¤æ–‡ä»¶
â”œâ”€â”€ pyproject.toml         # ä¾èµ–ç®¡ç†
â””â”€â”€ readme.md
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚
- Python 3.11+
- [uv](https://github.com/astral-sh/uv) åŒ…ç®¡ç†å™¨
- (å¯é€‰) CUDA 11.8+ / Apple Silicon

### 1ï¸âƒ£ å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/yourusername/House-prices-regression.git
cd House-prices-regression
```

### 2ï¸âƒ£ å®‰è£…ä¾èµ–

```bash
# å®‰è£… uv åŒ…ç®¡ç†å™¨ï¼ˆäºŒé€‰ä¸€ï¼‰
brew install uv                        # macOS Homebrew
# æˆ–ï¼š
curl -LsSf https://astral.sh/uv/install.sh | sh

# å‡†å¤‡ç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
uv python install 3.11                 # å®‰è£… Python 3.11
uv sync                                # åŒæ­¥ä¾èµ–ï¼ˆåŸºäº pyproject.tomlï¼‰
```

### 3ï¸âƒ£ å‡†å¤‡æ•°æ®

```bash
# ä¸‹è½½ç«èµ›æ•°æ®åˆ° data/ ç›®å½•
data/
â”œâ”€â”€ train.csv          # è®­ç»ƒæ•°æ®
â”œâ”€â”€ test.csv           # æµ‹è¯•æ•°æ®
â””â”€â”€ AmesHousing.csv    # (å¯é€‰) å¤–éƒ¨æ•°æ®å¢å¼º
```

> ğŸ’¡ **æç¤º**: AmesHousing.csv å¯ä» [Kaggle Datasets](https://www.kaggle.com/datasets) è·å–ï¼Œä½¿ç”¨åæ€§èƒ½æå‡ 77%ï¼

### 4ï¸âƒ£ è¿è¡Œè®­ç»ƒ

#### ğŸ† æ¨èæ–¹æ¡ˆï¼šXGBoost + Optuna ä¼˜åŒ– + æ•°æ®å¢å¼º
**ç›®æ ‡åˆ†æ•°**: 0.029 (ä¸æœ€ä½³æˆç»©ä¸€è‡´)

```bash
# ä½¿ç”¨ AmesHousing æ•°æ®å¢å¼º + GPU åŠ é€Ÿ + Optuna è´å¶æ–¯ä¼˜åŒ–
uv run python src/train_tree.py \
  --model xgb \
  --gpu \
  --tune \
  --n_iter 50 \
  --folds 5 \
  --include-ames \
  --ames-path data/AmesHousing.csv
```

#### ğŸ“Š å…¶ä»–è®­ç»ƒæ–¹æ¡ˆ

<details>
<summary><b>æ–¹æ¡ˆ1: GPU å®Œæ•´ Ensemble</b> (NN + XGBoost + LightGBM)</summary>

```bash
# ä¸‰æ¨¡å‹ stackingï¼Œé€‚ç”¨äº 48GB GPU
uv run python src/train_gpu_ensemble.py --folds 5

# ä½¿ç”¨ AmesHousing æ•°æ®å¢å¼º
uv run python src/train_gpu_ensemble.py --folds 5 --include-ames
```

**é¢„æœŸæ€§èƒ½**: CV ~0.11-0.12 | Kaggle ~0.126

</details>

<details>
<summary><b>æ–¹æ¡ˆ2: æ ‘æ¨¡å‹å¿«é€Ÿè°ƒå‚</b> (XGBoost/LightGBM/HGB)</summary>

```bash
# XGBoost (GPU åŠ é€Ÿ)
uv run python src/train_tree.py --model xgb --gpu --folds 5

# LightGBM (éœ€å…ˆå®‰è£…)
uv add lightgbm
uv run python src/train_tree.py --model lgbm --gpu --folds 5

# HistGradientBoosting (CPU å‹å¥½)
uv run python src/train_tree.py --model hgb --folds 5
```

**é¢„æœŸæ€§èƒ½**: CV ~0.116-0.120 | Kaggle ~0.123-0.127

</details>

<details>
<summary><b>æ–¹æ¡ˆ3: PyTorch MLP</b> (Apple Silicon MPS ä¼˜åŒ–)</summary>

```bash
# MacBook M4 MPS åŠ é€Ÿ
uv run python src/train_mps.py --device mps --epochs 200 --batch_size 512

# CUDA GPU
uv run python src/train_mps.py --device cuda --epochs 300 --batch_size 1024
```

**é¢„æœŸæ€§èƒ½**: CV ~0.130-0.135 | Kaggle ~0.243

</details>

---

## ğŸ“ˆ å®éªŒç»“æœ

### Kaggle Leaderboard è¡¨ç°

| æ¨¡å‹ | ä½¿ç”¨ AmesHousing | CV Score | Kaggle Score | æ’å |
|------|-----------------|----------|--------------|------|
| **XGBoost + Optuna** | âœ… | - | **0.02904** | **33/4,692** ğŸ† |
| LightGBM | âœ… | 0.116 | 0.03231 | - |
| XGBoost | âŒ | 0.116 | 0.12740 | - |
| GPU Ensemble | âŒ | 0.120 | 0.12561 | - |
| LightGBM | âŒ | 0.119 | 0.12303 | - |
| PyTorch MLP | âŒ | 0.130 | 0.24302 | - |

### æ ¸å¿ƒå‘ç°

#### ğŸ¯ æ•°æ®å¢å¼ºæ˜¯å…³é”®
```
ä¸ä½¿ç”¨ AmesHousing:  0.127 â†’ ä½¿ç”¨ AmesHousing: 0.029
                    æå‡å¹…åº¦: -77.2% âœ¨
```

#### ğŸ”¬ æ¨¡å‹å¯¹æ¯”
```
æ ‘æ¨¡å‹ (XGBoost/LightGBM)    > ç¥ç»ç½‘ç»œ (PyTorch)
   0.029-0.032                   0.243

å°æ•°æ®é›†ä¸‹ (1,460 æ ·æœ¬)ï¼Œæ ‘æ¨¡å‹æ˜¾è‘—ä¼˜äºæ·±åº¦å­¦ä¹ 
```

#### âš¡ Optuna vs éšæœºæœç´¢
```
Optuna è´å¶æ–¯ä¼˜åŒ–:  50 æ¬¡è¯•éªŒ â†’ æœ€ä¼˜è§£
RandomizedSearchCV:  150+ æ¬¡è¯•éªŒ â†’ ç›¸åŒæ•ˆæœ

æ•ˆç‡æå‡: 3-5 å€ ğŸš€
```

### æœ€ä½³è¶…å‚æ•°
```python
# XGBoost æœ€ä¼˜é…ç½® (Kaggle 0.02904)
best_params = {
    'n_estimators': 2200,
    'learning_rate': 0.045,
    'max_depth': 6,
    'subsample': 0.908,
    'colsample_bytree': 0.660,
    'reg_lambda': 1.815
}
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåï¼Œæäº¤æ–‡ä»¶ä¿å­˜åœ¨ `submissions/` ç›®å½•ï¼š

| æ–‡ä»¶å | å¯¹åº”è„šæœ¬ | é¢„æœŸåˆ†æ•° |
|--------|---------|---------|
| `submission_tree_xgb_tuned.csv` | `train_tree.py --model xgb --tune --include-ames` | **~0.029** ğŸ† |
| `submission_tree_lgbm.csv` | `train_tree.py --model lgbm --include-ames` | ~0.032 |
| `submission_gpu_ensemble.csv` | `train_gpu_ensemble.py` | ~0.126 |
| `submission_pytorch_mps.csv` | `train_mps.py` | ~0.243 |

## âš™ï¸ å‘½ä»¤è¡Œå‚æ•°

<details>
<summary><b>æŸ¥çœ‹æ‰€æœ‰å¯é…ç½®å‚æ•°</b></summary>

### train_tree.py (ä¸»æ¨è)
```bash
--model            # æ¨¡å‹é€‰æ‹©: hgb/rf/xgb/lgbm (é»˜è®¤ hgb)
--folds            # KæŠ˜äº¤å‰éªŒè¯æ•° (é»˜è®¤ 5)
--tune             # å¯ç”¨ Optuna è¶…å‚æ•°ä¼˜åŒ–
--n_iter           # ä¼˜åŒ–è¿­ä»£æ¬¡æ•° (é»˜è®¤ 40)
--gpu              # å¯ç”¨ GPU åŠ é€Ÿ
--include-ames     # ä½¿ç”¨ AmesHousing æ•°æ®å¢å¼º
--ames-path        # AmesHousing.csv è·¯å¾„
--seed             # éšæœºç§å­ (é»˜è®¤ 42)
```

### train_gpu_ensemble.py
```bash
--folds            # KæŠ˜äº¤å‰éªŒè¯æ•° (é»˜è®¤ 5)
--include-ames     # ä½¿ç”¨ AmesHousing æ•°æ®å¢å¼º
--seed             # éšæœºç§å­ (é»˜è®¤ 42)
```

### train_mps.py
```bash
--device           # è®¾å¤‡: cpu/cuda/mps (é»˜è®¤è‡ªåŠ¨)
--epochs           # è®­ç»ƒè½®æ•° (é»˜è®¤ 200)
--batch_size       # æ‰¹å¤§å° (é»˜è®¤ 512)
--hidden_dim       # éšè—å±‚ç»´åº¦ (é»˜è®¤ 256)
--lr               # å­¦ä¹ ç‡ (é»˜è®¤ 0.001)
--dropout          # Dropout ç‡ (é»˜è®¤ 0.3)
```

</details>

## ğŸ”§ è¿›é˜¶ä¼˜åŒ–å»ºè®®

æƒ³è¦è¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Ÿå°è¯•ä»¥ä¸‹æ–¹å‘ï¼š

### 1. æ¨¡å‹å¤šæ ·æ€§
- âœ¨ æ·»åŠ  **CatBoost** åˆ°é›†æˆæ¨¡å‹
- âœ¨ å°è¯• **TabNet** ç­‰è¡¨æ ¼ä¸“ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹
- âœ¨ æ¢ç´¢ **AutoML** æ¡†æ¶ (AutoGluon/H2O)

### 2. ç‰¹å¾å·¥ç¨‹
- ğŸ¯ **Target Encoding** for Neighborhood
- ğŸ¯ æ—¶åºå‘¨æœŸç‰¹å¾ï¼ˆå»ºé€ å¹´ä»½çš„å‘¨æœŸæ€§æ¨¡å¼ï¼‰
- ğŸ¯ æ›´å¤šé¢†åŸŸçŸ¥è¯†ç‰¹å¾ï¼ˆå¦‚å­¦åŒºã€äº¤é€šä¾¿åˆ©åº¦ï¼‰

### 3. æ•°æ®å¢å¼º
- ğŸ“Š èåˆæ›´å¤šå¤–éƒ¨æ•°æ®é›†
- ğŸ“Š ä½¿ç”¨æ•°æ®åˆæˆæŠ€æœ¯ (SMOTE/ADASYN)

### 4. é›†æˆç­–ç•¥
- ğŸ”¬ å¤šå±‚ Stacking (Level 3+)
- ğŸ”¬ ä½¿ç”¨æ›´å¤æ‚çš„ Meta-Learner
- ğŸ”¬ æ¨¡å‹æƒé‡çš„è´å¶æ–¯ä¼˜åŒ–

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ï¼å¦‚æœä½ æœ‰ä»»ä½•æ”¹è¿›å»ºè®®ï¼š

1. **Fork** æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ **Pull Request**

### è´¡çŒ®æ–¹å‘
- ğŸ› Bug ä¿®å¤
- âœ¨ æ–°æ¨¡å‹å®ç° (CatBoost/TabNet)
- ğŸ“ æ–‡æ¡£æ”¹è¿›
- âš¡ æ€§èƒ½ä¼˜åŒ–
- ğŸ§ª æ–°ç‰¹å¾å·¥ç¨‹ç­–ç•¥

## ğŸ™ è‡´è°¢

- **Kaggle** - æä¾›ä¼˜è´¨ç«èµ›å¹³å°å’Œæ•°æ®é›†
- **XGBoost/LightGBM å›¢é˜Ÿ** - ä¼˜ç§€çš„æ¢¯åº¦æå‡åº“
- **Optuna å¼€å‘è€…** - å¼ºå¤§çš„è¶…å‚æ•°ä¼˜åŒ–æ¡†æ¶
- **Ames Housing Dataset** - ç”± Dean De Cock ç¼–åˆ¶çš„å®Œæ•´æ•°æ®é›†

## ğŸ“š è¯¦ç»†æ–‡æ¡£

å®Œæ•´çš„å®éªŒè¿‡ç¨‹ã€æ–¹æ³•è®ºå’Œç»“æœåˆ†æè¯·å‚é˜…ï¼š
- ğŸ“„ [å®éªŒæŠ¥å‘Š](å®éªŒæŠ¥å‘Š.md) - è¯¦ç»†çš„å®éªŒè®°å½•å’Œåˆ†æ
- ğŸ“Š [Kaggle ç«èµ›é¡µé¢](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

## â“ å¸¸è§é—®é¢˜

<details>
<summary><b>Q: ä¸ºä»€ä¹ˆ PyTorch MLP è¡¨ç°æ¯”æ ‘æ¨¡å‹å·®å¾ˆå¤šï¼Ÿ</b></summary>

**A**: åœ¨å°æ•°æ®é›† (1,460 æ ·æœ¬) ä¸Šï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹éš¾ä»¥å……åˆ†å­¦ä¹ ã€‚æ ‘æ¨¡å‹ï¼ˆå¦‚ XGBoostï¼‰å¤©ç„¶é€‚åˆç»“æ„åŒ–æ•°æ®ä¸”å¯¹æ ·æœ¬é‡è¦æ±‚è¾ƒä½ã€‚å®éªŒæ˜¾ç¤ºï¼š
- æ ‘æ¨¡å‹ï¼š0.029-0.032
- ç¥ç»ç½‘ç»œï¼š0.243

**å»ºè®®**: å¦‚æœæ•°æ®é‡ < 10Kï¼Œä¼˜å…ˆä½¿ç”¨æ ‘æ¨¡å‹ã€‚
</details>

<details>
<summary><b>Q: å¿…é¡»ä½¿ç”¨ AmesHousing æ•°æ®é›†å—ï¼Ÿ</b></summary>

**A**: ä¸æ˜¯å¿…é¡»ï¼Œä½†å¼ºçƒˆæ¨èã€‚æ•°æ®å¢å¼ºåæ€§èƒ½æå‡ **77%**ï¼š
- ä¸ä½¿ç”¨: 0.127
- ä½¿ç”¨: 0.029

AmesHousing.csv åŒ…å«çº¦ 2,930 æ¡é¢å¤–è®°å½•ï¼Œæ˜¾è‘—æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚
</details>

<details>
<summary><b>Q: GPU åŠ é€Ÿæ•ˆæœå¦‚ä½•ï¼Ÿ</b></summary>

**A**: 
- **XGBoost GPU**: è®­ç»ƒé€Ÿåº¦æå‡ 5-10 å€
- **50 æ¬¡ Optuna è¯•éªŒ**: GPU çº¦ 10-20 åˆ†é’Ÿï¼ŒCPU éœ€ 1-2 å°æ—¶
- **æ¨èé…ç½®**: 48GB æ˜¾å­˜çš„ GPU (å¦‚ L20/A100)
</details>

<details>
<summary><b>Q: Optuna å’Œ RandomizedSearchCV å·®å¼‚ï¼Ÿ</b></summary>

**A**: Optuna ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ï¼Œæ•ˆç‡æå‡ 3-5 å€ï¼š

| æ–¹æ³• | è¾¾åˆ°æœ€ä¼˜éœ€è¦çš„è¯•éªŒæ¬¡æ•° | ä¼˜åŠ¿ |
|------|----------------------|------|
| Optuna | 50 æ¬¡ | TPE æ™ºèƒ½æœç´¢ + è‡ªåŠ¨å‰ªæ |
| RandomizedSearchCV | 150+ æ¬¡ | éšæœºæœç´¢ |
</details>

<details>
<summary><b>Q: å¦‚ä½•åœ¨ Macbook M4 ä¸Šè¿è¡Œï¼Ÿ</b></summary>

**A**: ä½¿ç”¨ MPS åŠ é€Ÿçš„ PyTorch è„šæœ¬ï¼š
```bash
uv run python src/train_mps.py --device mps --epochs 200
```

è™½ç„¶ MLP è¡¨ç°ä¸€èˆ¬ (0.243)ï¼Œä½†å¯ä½œä¸ºå­¦ä¹ å’Œå¿«é€Ÿè¿­ä»£çš„åŸºçº¿ã€‚
</details>

<details>
<summary><b>Q: æäº¤æ–‡ä»¶åœ¨å“ªé‡Œï¼Ÿ</b></summary>

**A**: æ‰€æœ‰ç”Ÿæˆçš„æäº¤æ–‡ä»¶ä¿å­˜åœ¨ `submissions/` ç›®å½•ï¼Œæ–‡ä»¶åæ ¼å¼ï¼š
```
submission_tree_xgb_tuned.csv    # XGBoost è°ƒä¼˜ç‰ˆ
submission_tree_lgbm.csv          # LightGBM
submission_gpu_ensemble.csv       # GPU Ensemble
submission_pytorch_mps.csv        # PyTorch MLP
```
</details>

## ğŸ“– å‚è€ƒèµ„æ–™

- [Kaggle House Prices Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [Optuna: A hyperparameter optimization framework](https://optuna.org/)
- [PyTorch MPS Backend](https://pytorch.org/docs/stable/notes/mps.html)

## â­ Star History

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ï¸ Star æ”¯æŒä¸€ä¸‹ï¼

## ğŸ“„ License

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

---

<div align="center">

**Made with â¤ï¸ by [](https://github.com/yourusername)**

*å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿æ [Issue](https://github.com/yourusername/House-prices-regression/issues)*

</div>
